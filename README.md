## Membership Inference Attack on Hyperdimensional Computing

Membership Inference Attacks (MIAs) pose a significant threat to the privacy of machine learning models by allowing adversaries to determine whether a specific data sample was part of a model’s training dataset. While extensive literature has explored MIAs in traditional machine learning models such as neural networks and decision trees, little attention has been given to their applicability in the emerging paradigm of Hyperdimensional Computing (HDC). This work pioneers the systematic exploration of MIAs in HDC models, which are increasingly being deployed in domains ranging from image classification to hardware security. We evaluate the susceptibility of HDC to MIAs using two diverse datasets: the MNIST image dataset and digital circuit netlists from ISCAS85 and ITC-99 benchmarks. We leverage multiple similarity-based metrics—Cosine, Euclidean, and Hamming distance—to distinguish training members from non-members. Our results demonstrate that the direct aggregation and transparent structure of HDC models make them more vulnerable to MIA compared to traditional ML models, which often abstract and obscure individual training contributions. 
